# -*- coding: utf-8 -*-
"""Demo_Attack.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TpwM4oZ1y1ZJisIMpBl9T7Epi2h2HoCq
"""

!pip install openai-whisper librosa jiwer soundfile matplotlib



"""
VISUAL DEMO: Word-Level Comparison with WER Calculation
========================================================
Shows transcription differences with highlighting + WER for all attacks
Perfect for presentation - no audio playback needed!
UPDATED: Using adversarial_audio_highfreq_12_19kHz folder
"""

from google.colab import drive
import os
import whisper
from jiwer import wer
import librosa
from difflib import SequenceMatcher
from IPython.display import HTML, display

# ============================================================================
# STEP 1: SETUP
# ============================================================================

print("="*70)
print("üéØ VISUAL ATTACK DEMONSTRATION")
print("="*70)

drive.mount('/content/drive')
os.chdir('/content/drive/My Drive/Adversarial_Audio Attack Project')

print("\nüì¶ Installing libraries...")
!pip install -q openai-whisper jiwer librosa

import whisper
from jiwer import wer

print("‚úì Libraries installed!")

# ============================================================================
# STEP 2: LOAD WHISPER MODEL
# ============================================================================

print("\nü§ñ Loading Whisper model...")
model = whisper.load_model("base")
print("‚úì Whisper model loaded!")

# ============================================================================
# STEP 3: SELECT FILES TO TEST
# ============================================================================

print("\nüìÇ Selecting test files...")

audio_files = sorted([f for f in os.listdir('clean_audio') if f.endswith(('.wav', '.flac', '.mp3'))])

DEMO_INDEX = 0
demo_file = audio_files[DEMO_INDEX]
base_name = os.path.splitext(demo_file)[0]

print(f"‚úì Selected: {base_name}")

files_to_test = {
    'clean': f'clean_audio/{demo_file}',
    'high_freq': f'adversarial_audio_highfreq_12_19kHz/{base_name}_freq12000_amp0.010.wav',
    'white_noise': f'adversarial_audio_whitenoise/{base_name}_noise0.0500.wav'
}

print("\nüìã File status:")
for attack_type, filepath in files_to_test.items():
    status = "‚úì FOUND" if os.path.exists(filepath) else "‚úó NOT FOUND"
    print(f"  {attack_type}: {status}")

# ============================================================================
# STEP 4: TRANSCRIBE ALL FILES
# ============================================================================

print("\n" + "="*70)
print("ü§ñ TRANSCRIBING FILES")
print("="*70)

transcriptions = {}

for attack_type, filepath in files_to_test.items():
    if os.path.exists(filepath):
        print(f"\nTranscribing {attack_type}...")
        result = model.transcribe(filepath)
        transcriptions[attack_type] = result["text"]
        print(f"‚úì {attack_type}: '{result['text'][:60]}...'")
    else:
        transcriptions[attack_type] = None
        print(f"‚ö†Ô∏è  {attack_type}: File not found")

# ============================================================================
# STEP 5: CALCULATE WER
# ============================================================================

print("\n" + "="*70)
print("üìä CALCULATING WORD ERROR RATES")
print("="*70)

clean_text = transcriptions['clean']
wer_results = {}

if clean_text:
    wer_results['clean'] = {
        'wer': 0.0,
        'wer_percent': "0.0%",
        'status': "‚úÖ Correct",
        'transcription': clean_text
    }

    if transcriptions['high_freq']:
        hf_wer = wer(clean_text, transcriptions['high_freq'])
        wer_results['high_freq'] = {
            'wer': hf_wer,
            'wer_percent': f"{hf_wer*100:.1f}%",
            'status': "üî• STRONG" if hf_wer > 0.3 else "‚ö†Ô∏è MODERATE" if hf_wer > 0.1 else "~ WEAK",
            'transcription': transcriptions['high_freq']
        }

    if transcriptions['white_noise']:
        wn_wer = wer(clean_text, transcriptions['white_noise'])
        wer_results['white_noise'] = {
            'wer': wn_wer,
            'wer_percent': f"{wn_wer*100:.1f}%",
            'status': "üî• STRONG" if wn_wer > 0.3 else "‚ö†Ô∏è MODERATE" if wn_wer > 0.1 else "~ WEAK",
            'transcription': transcriptions['white_noise']
        }

# ============================================================================
# STEP 6: HIGHLIGHT FUNCTION  (LEGEND REMOVED)
# ============================================================================

def highlight_differences(clean_text, attacked_text, attack_name, wer_percent, status):

    clean_words = clean_text.lower().split()
    attacked_words = attacked_text.lower().split()
    matcher = SequenceMatcher(None, clean_words, attacked_words)

    html = f"""
    <style>
        .comparison-container {{
            font-family: 'Segoe UI', Arial, sans-serif;
            margin: 30px 0;
            border: 3px solid #ddd;
            border-radius: 12px;
            padding: 20px;
            background-color: #f9f9f9;
        }}
        .attack-header {{
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 15px 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }}
        .attack-name {{
            font-size: 22px;
            font-weight: bold;
        }}
        .attack-wer {{
            font-size: 28px;
            font-weight: bold;
            background-color: rgba(255,255,255,0.2);
            padding: 5px 15px;
            border-radius: 6px;
        }}
        .text-box {{
            padding: 20px;
            margin: 10px 0;
            border-radius: 8px;
            font-size: 16px;
            line-height: 2;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }}
        .clean-box {{
            background-color: #d4edda;
            border: 2px solid #28a745;
        }}
        .attacked-box {{
            background-color: #f8d7da;
            border: 2px solid #dc3545;
        }}
        .correct-word {{
            background-color: #28a745;
            color: white;
            padding: 3px 8px;
            border-radius: 4px;
            margin: 0 3px;
        }}
        .wrong-word {{
            background-color: #dc3545;
            color: white;
            padding: 3px 8px;
            border-radius: 4px;
            margin: 0 3px;
        }}
        .inserted-word {{
            background-color: #ffc107;
            color: black;
            padding: 3px 8px;
            border-radius: 4px;
            margin: 0 3px;
        }}
        .deleted-word {{
            background-color: #6c757d;
            color: white;
            padding: 3px 8px;
            border-radius: 4px;
            margin: 0 3px;
            opacity: 0.5;
        }}
    </style>

    <div class="comparison-container">
        <div class="attack-header">
            <div class="attack-name">{attack_name}</div>
            <div>
                <span class="attack-wer">{wer_percent}</span>
                <span style="margin-left: 15px;">{status}</span>
            </div>
        </div>
    """

    # Clean transcription block
    html += """
        <div class="label">‚úÖ CLEAN TRANSCRIPTION:</div>
        <div class="text-box clean-box">
    """

    for opcode, i1, i2, j1, j2 in matcher.get_opcodes():
        if opcode == 'equal':
            for w in clean_words[i1:i2]:
                html += f'<span class="correct-word">{w}</span> '
        else:
            for w in clean_words[i1:i2]:
                html += f'<span class="deleted-word">{w}</span> '

    html += """
        </div>
        <div class="label">‚ùå ATTACKED TRANSCRIPTION:</div>
        <div class="text-box attacked-box">
    """

    for opcode, i1, i2, j1, j2 in matcher.get_opcodes():
        if opcode == 'equal':
            for w in attacked_words[j1:j2]:
                html += f'<span class="correct-word">{w}</span> '
        elif opcode == 'replace':
            for w in attacked_words[j1:j2]:
                html += f'<span class="wrong-word">{w}</span> '
        elif opcode == 'insert':
            for w in attacked_words[j1:j2]:
                html += f'<span class="inserted-word">{w}</span> '

    # LEGEND REMOVED HERE ‚Äî CLEAN OUTPUT ONLY

    html += "</div></div>"

    return html

# ============================================================================
# STEP 7: GENERATE VISUALS
# ============================================================================

print("\n" + "="*70)
print("üé® Generating comparisons...")
print("="*70)

title_html = """
<div style="text-align:center; margin:30px;">
    <h1 style="font-size:36px; color:#2c3e50;">üéØ Adversarial Audio Attack Demonstration</h1>
    <p style="font-size:18px; color:#7f8c8d;">Word-Level Transcription Corruption Analysis</p>
</div>
"""
display(HTML(title_html))

if 'high_freq' in wer_results:
    html_hf = highlight_differences(
        clean_text,
        wer_results['high_freq']['transcription'],
        "High-Frequency Attack (12kHz)",
        wer_results['high_freq']['wer_percent'],
        wer_results['high_freq']['status']
    )
    display(HTML(html_hf))

if 'white_noise' in wer_results:
    html_wn = highlight_differences(
        clean_text,
        wer_results['white_noise']['transcription'],
        "White Noise Attack (5% level)",
        wer_results['white_noise']['wer_percent'],
        wer_results['white_noise']['status']
    )
    display(HTML(html_wn))

# ============================================================================
# STEP 8: SUMMARY
# ============================================================================

print("\n" + "="*70)
print("üìä SUMMARY STATISTICS")
print("="*70)

summary_html = """
<div style="margin:30px 0; padding:30px; background: linear-gradient(135deg, #667eea, #764ba2); border-radius:12px; color:white;">
    <h2 style="text-align:center; margin-bottom:30px;">Attack Effectiveness Summary</h2>
    <div style="display:grid; grid-template-columns:repeat(3,1fr); gap:20px;">
"""
for attack_type, results in wer_results.items():
    name_map = {
        'clean': 'Clean (Baseline)',
        'high_freq': 'High-Frequency (12kHz)',
        'white_noise': 'White Noise (5%)'
    }
    summary_html += f"""
        <div style="background-color:rgba(255,255,255,0.15); padding:20px; border-radius:8px; text-align:center;">
            <div style="font-size:18px;">{name_map.get(attack_type, attack_type)}</div>
            <div style="font-size:48px; font-weight:bold;">{results['wer_percent']}</div>
            <div style="padding:8px; border-radius:6px; background-color:#00000055;">
                {results['status']}
            </div>
        </div>
    """
summary_html += "</div></div>"

display(HTML(summary_html))

print("\n" + "="*70)
print("‚úÖ COMPLETE VISUAL DEMO READY")
print("="*70)